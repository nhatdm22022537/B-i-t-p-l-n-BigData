{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SPARK_HOME'] = \"/opt/spark/spark-3.4.3-bin-hadoop3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/28 07:12:37 WARN Utils: Your hostname, nhatdm2k4 resolves to a loopback address: 127.0.1.1; using 192.168.1.49 instead (on interface wlo1)\n",
      "24/05/28 07:12:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/28 07:12:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Set up Spark configuration\n",
    "conf = SparkConf() \\\n",
    "    .setAppName(\"ALS Model\") \\\n",
    "    .setMaster(\"spark://nhatdm2k4:7077\") \\\n",
    "    .set(\"spark.driver.memory\", \"8g\") \\\n",
    "    .set(\"spark.executor.memory\", \"8g\")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "df = spark.read.csv('final_dataset.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = df.withColumn(\"User_Id\", col(\"User_Id\").cast(\"integer\"))\n",
    "df = df.withColumn(\"Movie_ID\", col(\"Movie_ID\").cast(\"integer\"))\n",
    "df = df.withColumn(\"Rating\", col(\"Rating\").cast(\"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, test) = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "als = ALS(\n",
    "    maxIter=10,\n",
    "    regParam=0.1,\n",
    "    userCol=\"User_Id\",\n",
    "    itemCol=\"Movie_ID\",\n",
    "    ratingCol=\"Rating\",\n",
    "    coldStartStrategy=\"drop\"\n",
    ")\n",
    "\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.8078979668028524\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"Rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "predictions = model.transform(test)\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root-mean-square error = {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 550:==================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+----------+\n",
      "|          Movie_Name|  Year|prediction|\n",
      "+--------------------+------+----------+\n",
      "|Born in the USSR:...|2005.0| 5.8548536|\n",
      "|          Adrenaline|1990.0|  6.451732|\n",
      "|             Acı Aşk|2009.0| 6.0834537|\n",
      "|           The Thorn|1971.0| 6.5986204|\n",
      "|NOFX Backstage Pa...|  null| 6.2526855|\n",
      "+--------------------+------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "# Assume 'user_id' is the user for whom we want to recommend movies\n",
    "user_id = 69\n",
    "\n",
    "# Generate a DataFrame with all possible user-movie combinations for the given user\n",
    "user_movies = (\n",
    "    training.select('Movie_ID').distinct()\n",
    "    .withColumn('User_Id', lit(user_id))\n",
    ")\n",
    "\n",
    "# Predict ratings for these user-movie combinations\n",
    "predictions = model.transform(user_movies)\n",
    "\n",
    "# Filter out the movies the user has already rated\n",
    "rated_movies = training.filter(col('User_Id') == user_id).select('Movie_ID')\n",
    "predictions = predictions.join(rated_movies, 'Movie_ID', 'left_anti')\n",
    "\n",
    "# Get top 5 recommendations\n",
    "top_5_recommendations = predictions.orderBy(col('prediction').desc()).limit(5)\n",
    "\n",
    "# Join with the original dataset to get movie details\n",
    "top_5_details = top_5_recommendations.join(training.select('Movie_ID', 'Movie_Name', 'Year').distinct(), on='Movie_ID')\n",
    "\n",
    "# Show the top 5 recommended movies with their names and years\n",
    "top_5_details.select('Movie_Name', 'Year', 'prediction').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 750:==================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+----------+\n",
      "|          Movie_Name|  Year|prediction|\n",
      "+--------------------+------+----------+\n",
      "|        Civilisation|1969.0| 6.0659013|\n",
      "|   Truth and Justice|2019.0| 6.3914495|\n",
      "|          Adrenaline|1990.0| 6.5918508|\n",
      "|             Acı Aşk|2009.0|  7.182456|\n",
      "|Täällä Pohjantähd...|1968.0| 6.0449433|\n",
      "+--------------------+------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "user_id = 22345\n",
    "\n",
    "# Generate a DataFrame with all possible user-movie combinations for the given user\n",
    "user_movies = (\n",
    "    training.select('Movie_ID').distinct()\n",
    "    .withColumn('User_Id', lit(user_id))\n",
    ")\n",
    "\n",
    "# Predict ratings for these user-movie combinations\n",
    "predictions = model.transform(user_movies)\n",
    "\n",
    "# Filter out the movies the user has already rated\n",
    "rated_movies = training.filter(col('User_Id') == user_id).select('Movie_ID')\n",
    "predictions = predictions.join(rated_movies, 'Movie_ID', 'left_anti')\n",
    "\n",
    "# Get top 5 recommendations\n",
    "top_5_recommendations = predictions.orderBy(col('prediction').desc()).limit(5)\n",
    "\n",
    "# Join with the original dataset to get movie details\n",
    "top_5_details = top_5_recommendations.join(training.select('Movie_ID', 'Movie_Name', 'Year').distinct(), on='Movie_ID')\n",
    "\n",
    "# Show the top 5 recommended movies with their names and years\n",
    "top_5_details.select('Movie_Name', 'Year', 'prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+----------+\n",
      "|User_Id|Movie_ID|prediction|\n",
      "+-------+--------+----------+\n",
      "|      1|      10| 3.6942236|\n",
      "|      1|      20|  3.990606|\n",
      "|      2|      10| 3.8788896|\n",
      "+-------+--------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/28 05:54:25 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED\n",
      "24/05/28 05:54:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exiting due to error from cluster scheduler: Master removed our application: KILLED\n",
      "\tat org.apache.spark.errors.SparkCoreErrors$.clusterSchedulerError(SparkCoreErrors.scala:291)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.error(TaskSchedulerImpl.scala:978)\n",
      "\tat org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.dead(StandaloneSchedulerBackend.scala:165)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint.markDead(StandaloneAppClient.scala:263)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1.applyOrElse(StandaloneAppClient.scala:170)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALSModel\n",
    "\n",
    "# Load the model from the specified directory\n",
    "loaded_model = ALSModel.load(\"/home/nhatdm2k4/Documents/test/als_final_model\")\n",
    "\n",
    "# Example DataFrame for inference\n",
    "new_data = spark.createDataFrame([\n",
    "    (1, 10),  # (User_Id, Movie_ID)\n",
    "    (1, 20),\n",
    "    (2, 10)\n",
    "], [\"User_Id\", \"Movie_ID\"])\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "predictions = loaded_model.transform(new_data)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_movies = df.select(\"Movie_ID\", \"Movie_Name\", \"Year\").distinct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+--------------------+------+--------+\n",
      "|User_Id|          Movie_Name|Rating|               Genre|  Year|Movie_ID|\n",
      "+-------+--------------------+------+--------------------+------+--------+\n",
      "|      1|        Pulp Fiction|   5.0|Comedy|Crime|Dram...|1994.0|       1|\n",
      "|      1|Three Colors: Red...|   3.5|               Drama|1994.0|       2|\n",
      "|      1|Three Colors: Blu...|   5.0|               Drama|1993.0|       3|\n",
      "|      1|         Underground|   5.0|    Comedy|Drama|War|1995.0|       4|\n",
      "|      1| Singin' in the Rain|   3.5|Comedy|Musical|Ro...|1952.0|       5|\n",
      "|      1|       Dirty Dancing|   4.0|Drama|Musical|Rom...|1987.0|       6|\n",
      "|      1|        Delicatessen|   3.5|Comedy|Drama|Romance|1991.0|       7|\n",
      "|      1|                 Ran|   3.5|           Drama|War|1985.0|       8|\n",
      "|      1|Seventh Seal, The...|   5.0|               Drama|1957.0|       9|\n",
      "|      1|Bridge on the Riv...|   4.0| Adventure|Drama|War|1957.0|      10|\n",
      "|      1|                   M|   3.5|Crime|Film-Noir|T...|1931.0|      11|\n",
      "|      1|             Gattaca|   4.0|Drama|Sci-Fi|Thri...|1997.0|      12|\n",
      "|      1|Back to the Futur...|   2.5|Adventure|Comedy|...|1989.0|      13|\n",
      "|      1|Back to the Futur...|   2.5|Adventure|Comedy|...|1990.0|      14|\n",
      "|      1|Fanny and Alexand...|   2.5|Drama|Fantasy|Mys...|1982.0|      15|\n",
      "|      1|NeverEnding Story...|   3.5|Adventure|Childre...|1984.0|      16|\n",
      "|      1|Nights of Cabiria...|   4.5|               Drama|1957.0|      17|\n",
      "|      1|               Tango|   4.0|       Drama|Musical|1998.0|      18|\n",
      "|      1|Saragossa Manuscr...|   5.0|Adventure|Drama|M...|1965.0|      19|\n",
      "|      1|Run Lola Run (Lol...|   5.0|        Action|Crime|1998.0|      20|\n",
      "+-------+--------------------+------+--------------------+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 134:=============================================>         (10 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+------+\n",
      "|Movie_ID|          Movie_Name|  Year|\n",
      "+--------+--------------------+------+\n",
      "|     119|Star Trek: First ...|1996.0|\n",
      "|     308|         Skulls, The|2000.0|\n",
      "|     765|                Lucy|2014.0|\n",
      "|    1273|Hudsucker Proxy, The|1994.0|\n",
      "|    1495|       Wayne's World|1992.0|\n",
      "|    1520|           Bamba, La|1987.0|\n",
      "|    1580|Witness for the P...|1957.0|\n",
      "|    1641|Edukators, The (D...|2004.0|\n",
      "|    1690|      Batman Returns|1992.0|\n",
      "|    1879|Visitors, The (Vi...|1993.0|\n",
      "|    2022|Insidious: Chapter 2|2013.0|\n",
      "|    2716|Squid and the Wha...|2005.0|\n",
      "|    3179|       Summer of Sam|1999.0|\n",
      "|    3241|       Maid to Order|1987.0|\n",
      "|    3342|      Get the Gringo|2012.0|\n",
      "|    3546|      One Trick Pony|1980.0|\n",
      "|    3580|               Angus|1995.0|\n",
      "|    3622| Crazy for Christmas|2005.0|\n",
      "|    3681|Legend of the Gal...|1988.0|\n",
      "|    3952|          Ride Along|2014.0|\n",
      "+--------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "all_movies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine-tuning\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(als.rank, [10, 50, 100]) \\\n",
    "    .addGrid(als.regParam, [0.01, 0.1, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(\n",
    "    estimator=als,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3\n",
    ")\n",
    "\n",
    "cvModel = crossval.fit(training)\n",
    "\n",
    "bestModel = cvModel.bestModel\n",
    "predictions = bestModel.transform(test)\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Best model Root-mean-square error = {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
